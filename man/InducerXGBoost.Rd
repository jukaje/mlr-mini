% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/Inducer.R
\name{InducerXGBoost}
\alias{InducerXGBoost}
\title{Inducer for XGBoost}
\usage{
InducerXGBoost(
  .data,
  eta = NULL,
  nrounds = NULL,
  max_depth = NULL,
  colsample_bytree = NULL,
  colsample_bylevel = NULL,
  lambda = NULL,
  alpha = NULL,
  subsample = NULL,
  verbose = 0
)
}
\arguments{
\item{.data}{dataset object of class 'Dataset'}

\item{eta}{control the learning rate. Default: 0.3}

\item{nrounds}{max number of boosting iterations}

\item{max_depth}{maximum depth of a tree. Default: 6}

\item{colsample_bytree}{subsample ratio of columns when constructing each tree. Default: 1}

\item{lambda}{L2 regularization term on weights. Default: 1}

\item{alpha}{L1 regularization from on weights. Default: 0}

\item{subsample}{subsample ratio of the training instance. Default: 1}

\item{verbose}{If 0, no informations will be printed. If 1, it will print informations about performances. If 2,additional information will be printed.}
}
\description{
Inducer for XGBoost
}
\examples{
cars.data <- Dataset(cars, "dist", type = "regression")
xgb <- InducerXGBoost(nrounds = 10)
mod <- xgb(cars.data)

mod <- InducerXGBoost(cars.data, nrounds = 10)
}
